## 1. 模型设计思路
本项目实现了两种用于雷达图像预测的深度学习模型：LSTM-CNN混合模型和基于Vision Transformer的模型（SimpleViT）。两种模型各有优势，旨在通过不同的架构思路解决雷达图像序列预测问题。

### 1.1 LSTM-CNN 混合模型
LSTM-CNN模型采用编码器-解码器架构，专为捕捉雷达图像中的时空特征而设计：

核心组件：

1. 编码器（Encoder）：
   
   - 由多个卷积层和池化层构成
   - 使用逐步降采样策略：通道数从8→16→32递增，同时空间尺寸逐渐减小
   - 每一层包含卷积层、批归一化、ReLU激活和最大池化
   - 目的：高效提取雷达图像中的空间特征
2. ConvLSTM单元：
   
   - 融合了CNN的空间特征提取能力和LSTM的时间序列建模能力
   - 包含输入门、遗忘门和输出门的门控机制
   - 能够有效捕捉雷达序列中的长期依赖关系
3. 解码器（Decoder）：
   
   - 使用转置卷积层进行上采样
   - 通道数从32→16→8递减，恢复到原始图像尺寸
   - 最终通过Sigmoid激活将输出归一化到[0,1]范围
设计优势：

- 编码器-解码器结构能够有效处理雷达图像数据的时空特性
- ConvLSTM比普通LSTM更适合处理高维空间特征
- 逐步降采样和上采样策略保留了重要的空间细节信息
### 1.2 SimpleViT 模型
SimpleViT模型基于Transformer架构，通过自注意力机制捕捉雷达图像中的复杂依赖关系：

核心组件：

1. 增强版Patch Embedding：
   
   - 使用双卷积结构：先通过3×3卷积增加感受野，再通过patch_size×patch_size卷积进行嵌入
   - 相比标准ViT，增加了局部特征提取能力
2. ViT层：
   
   - 包含层归一化、多头自注意力机制和前馈网络
   - 使用GELU激活函数提高非线性建模能力
   - 添加Dropout层增强模型稳定性和泛化能力
3. LSTM时间序列处理：
   
   - 在Transformer编码器后添加LSTM处理时间维度
   - 利用LSTM的门控机制捕捉时间动态特性
4. 增强的输出层：
   
   - 使用多层全连接网络进行特征投影
   - 通过重构将patch特征转换回完整图像
设计优势：

- 自注意力机制能够捕捉长距离依赖关系
- 增强的patch embedding结构结合了CNN的局部特征提取能力
- 多层设计（embed_dim=256, num_heads=4, depth=3）提供了足够的表达能力
## 2. 实验过程
### 2.1 模型评估配置
实验评估使用以下配置：

- 评估样本数量：10个样本
- 损失函数：均方误差（MSE）
- 评估指标：平均MSE损失
- 可视化：生成单帧图像和GIF动画展示预测结果
### 2.2 模型加载与权重处理
LSTM-CNN模型加载：

- 直接加载预训练权重，架构与训练时保持一致
- 权重加载成功，无需额外处理
SimpleViT模型权重处理：

- 处理架构差异，进行权重映射：
  1. 将单卷积层的patch_embed.proj映射到双卷积层的patch_embed.0
  2. 调整位置编码维度以匹配目标形状
  3. 对形状匹配的其他权重进行直接加载
- 采用严格的权重映射策略，尽可能避免使用默认初始化
### 2.3 评估流程
1. 数据准备：
   
   - 从测试数据集中随机选择样本
   - 构建数据加载器，批量处理输入数据
2. 模型预测：
   
   - 输入历史雷达图像序列
   - 预测未来的雷达图像帧序列
3. 性能计算：
   
   - 计算预测结果与真实值之间的MSE损失
   - 统计平均损失值作为模型性能指标
4. 结果可视化：
   
   - 保存关键帧图像（输入的最后一帧、预测的第一帧和最后一帧、真实对应帧）
   - 生成GIF动画展示完整的预测过程
   - 并排显示预测结果与真实值，便于直观比较
## 3. 初步结果
### 3.1 模型性能比较
评估结果显示两种模型的性能存在显著差异：

模型	    平均MSE损失
LSTM-CNN	0.003370
SimpleViT	0.002914
关键发现：

- SimpleViT模型表现明显优于LSTM-CNN模型

### 3.2 可视化结果
成功生成了多个样本的可视化结果：

- 每个样本包含关键帧图像（输入、预测、真实值）
- 生成了预测过程的GIF动画，直观展示模型预测效果
- 可视化结果保存在 vis_results 目录下
- 模型训练的参数保存在checkpoints目录下
