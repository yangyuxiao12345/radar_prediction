# 项目阶段总结：雷达回波数据的清洗、序列化与工程优化
**Phase Report: Radar Data ETL & Sequence Construction**

**日期**：2025-11-19
**数据源**：华南地区雷达拼图 (32,000+帧)
**目标**：构建 `(Batch, 20, 1, 512, 512)` 的时空序列，用于 ConvLSTM 短临预报训练。
### 1. 数据背景与核心挑战
我们的数据如图所示：
![[20250720_004200.png]]

我们手中的原始数据是未经处理的 RGB 气象拼图（如上图）。在将其转化为模型可用的 Tensor 过程中，我们面临了三个主要障碍：

1.  **“脏数据”干扰**：大湾区密集的城市地名、海岸线、省界混杂在雷达回波中。若直接训练，模型会将这些静止的线条误判为云团特征（即“鬼影”现象）。
2.  **物理一致性破坏（对流空洞）**：当我们通过颜色阈值强制滤除文字（置为0）后，强回波中心（如台风眼壁）会出现密集的小黑洞，破坏了流体的连续性。
3.  **工程瓶颈**：3.2万张 `512x512` 的 float32 数据若直接保存为 `.npy`，体积超过 **500GB**，导致内存溢出且无法进行 I/O。

---

### 2. 解决方案与技术路线

经过多次迭代，我确定了 **V3 (最终版)** 处理流水线。

#### 2.1 空间域：非对称形态学修复 (Asymmetric Morphology)

为了解决“滤除文字后留下的空洞”，我们观察到地图上的地名标签通常是**扁长形**的（水平排列）。因此，我们摒弃了常规的方形核，设计了 **$4 \times 8$ 的矩形卷积核** 进行闭运算。

*   **原理**：在水平方向上具有更强的“愈合”能力，能连接被文字打断的回波；而在垂直方向保持较小的感受野，避免粘连上下层无关的云团。
*   **KDTree 映射**：使用 KDTree 替代简单的 RGB 范围判断，精确剔除背景杂色。

**核心代码片段：数据清洗与修复**
```python
def load_and_clean(self, path):
    # ... (读取与裁剪代码略)
    
    # 1. 等比例缩放 + 填充 (防止物理形变)
    img = resize_pad(img, CONFIG['img_size'])
    
    # 2. KDTree 映射 (RGB -> dBZ)
    dbz = rgb_to_dbz_kdtree(img)
    
    # 3. 【关键策略】非对称形态学闭运算
    # 使用 (4, 8) 核，针对性修复扁长的文字空洞
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (4, 8))
    dbz = cv2.morphologyEx(dbz, cv2.MORPH_CLOSE, kernel)
    
    # 4. 中值滤波去噪
    dbz = cv2.medianBlur(dbz, 3)

    return dbz
```


#### 2.2 时间域：光流插值与硬切分
因为我们的数据收集过程中发生过中断，中断

*   **微小中断 (<30min)**：采用 **Farneback 稠密光流法**。相比线性插值，光流法能根据云团的运动矢量推演中间帧，避免了“重影”问题。
*   **严重中断 (>30min)**：强制切断序列，防止模型学习到错误的时间跳变。

**核心代码片段：光流插值**
```python
def optical_flow_interpolation(frame_prev, frame_next, num_frames_to_insert):
    # 计算稠密光流场
    flow = cv2.calcOpticalFlowFarneback(
        frame_prev, frame_next, None, 
        pyr_scale=0.5, levels=3, winsize=15, iterations=3, poly_n=5, poly_sigma=1.2, flags=0
    )
    
    # ... (省略网格生成代码)
    
    # 基于光流场重映射 (Remap) 生成中间帧
    interp_frame = cv2.remap(frame_prev, map_x, map_y, cv2.INTER_LINEAR)
    return generated_frames
```

#### 2.3 工程优化：Lazy Loading 存储策略

为了解决 500GB 数据无法加载的问题，我们采用了 **“PNG单帧存储 + TXT索引”** 的方案：

1.  **预处理阶段**：将清洗好的 float32 数据转为 `uint8` (0-255) 的 **PNG 灰度图**保存。总积缩小至约 **4GB**。
2.  **训练阶段**：DataLoader 只读取 `train_list.txt` 中的索引，训练时实时读取图片。这极大降低了内存占用。

**核心代码片段：序列索引生成**
```python
# 仅在满足回波占比 > 5% 时，才将序列写入列表
if total_nz < min_pixels:
    continue # 丢弃无效的空序列

filenames = [item[0] for item in seq_meta]
line = ",".join(filenames) + "\n"
f.write(line) # 写入 train_list.txt
```

---

### 3. 结果评估

我们对处理后的数据进行了多维度的评估：

1.  **视觉检查**：台风眼结构清晰完整，螺旋雨带平滑，未发现地名文字残留，证明 $4 \times 8$ 核策略有效。
2.  **物理分布**：直方图显示数据符合长尾分布，保留了极值（>60dBZ），证明极值信息未丢失。
3.  **时序平滑度**：帧间差分曲线平缓，插值帧与真实帧过渡自然。


### 4. 结论
处理后结果，提取20帧做成gif。
![[eval_sample.gif]]
目前，数据预处理脚本 `radar_etl_storage_optimized.py` 已在全量数据集上运行完毕。
我们获得了：
1.  **processed_data/images/**: 约3.2万张清洗干净的 PNG 图片。
2.  **processed_data/train_list.txt**: 包含有效训练序列索引的文件。

**下一步计划**：编写 `Dataset` 类加载该 TXT 文件，直接开始 ConvLSTM 模型的训练。